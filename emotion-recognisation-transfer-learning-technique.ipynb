{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/anandkumar840972/emotion-recognisation-transfer-learning-technique?scriptVersionId=132647075\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# 1.Import all the libraries thats needed","metadata":{}},{"cell_type":"code","source":"from keras.layers import Input,Lambda,Dense,Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-06-07T09:44:33.057348Z","iopub.execute_input":"2023-06-07T09:44:33.057739Z","iopub.status.idle":"2023-06-07T09:44:33.063743Z","shell.execute_reply.started":"2023-06-07T09:44:33.057707Z","shell.execute_reply":"2023-06-07T09:44:33.06278Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"Image_size=[224,224]","metadata":{"execution":{"iopub.status.busy":"2023-06-07T09:53:21.447204Z","iopub.execute_input":"2023-06-07T09:53:21.44814Z","iopub.status.idle":"2023-06-07T09:53:21.453127Z","shell.execute_reply.started":"2023-06-07T09:53:21.448096Z","shell.execute_reply":"2023-06-07T09:53:21.452201Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_path=\"/kaggle/input/emotion-detection-fer/train\"","metadata":{"execution":{"iopub.status.busy":"2023-06-07T09:54:10.385835Z","iopub.execute_input":"2023-06-07T09:54:10.386175Z","iopub.status.idle":"2023-06-07T09:54:10.390958Z","shell.execute_reply.started":"2023-06-07T09:54:10.386145Z","shell.execute_reply":"2023-06-07T09:54:10.389895Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test_path=\"/kaggle/input/emotion-detection-fer/test\"","metadata":{"execution":{"iopub.status.busy":"2023-06-07T09:54:38.283069Z","iopub.execute_input":"2023-06-07T09:54:38.283768Z","iopub.status.idle":"2023-06-07T09:54:38.28839Z","shell.execute_reply.started":"2023-06-07T09:54:38.283734Z","shell.execute_reply":"2023-06-07T09:54:38.287152Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"vgg=VGG16(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=Image_size+[3],\n       )","metadata":{"execution":{"iopub.status.busy":"2023-06-07T09:59:14.564034Z","iopub.execute_input":"2023-06-07T09:59:14.564398Z","iopub.status.idle":"2023-06-07T09:59:21.461605Z","shell.execute_reply.started":"2023-06-07T09:59:14.564366Z","shell.execute_reply":"2023-06-07T09:59:21.460672Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in vgg.layers:\n    layer.trainable=False","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:00:12.585735Z","iopub.execute_input":"2023-06-07T10:00:12.586092Z","iopub.status.idle":"2023-06-07T10:00:12.591352Z","shell.execute_reply.started":"2023-06-07T10:00:12.586061Z","shell.execute_reply":"2023-06-07T10:00:12.590458Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"training_dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# number of the classes we will find..\n","metadata":{}},{"cell_type":"code","source":"folders=glob(\"/kaggle/input/emotion-detection-fer/train/*\")","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:06:37.930755Z","iopub.execute_input":"2023-06-07T10:06:37.931141Z","iopub.status.idle":"2023-06-07T10:06:37.972762Z","shell.execute_reply.started":"2023-06-07T10:06:37.931109Z","shell.execute_reply":"2023-06-07T10:06:37.971925Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Flatten the output off vgg\n\nx=Flatten()(vgg.output)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:06:46.973365Z","iopub.execute_input":"2023-06-07T10:06:46.973729Z","iopub.status.idle":"2023-06-07T10:06:46.98458Z","shell.execute_reply.started":"2023-06-07T10:06:46.973699Z","shell.execute_reply":"2023-06-07T10:06:46.983307Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(len(folders))","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:06:42.35243Z","iopub.execute_input":"2023-06-07T10:06:42.352791Z","iopub.status.idle":"2023-06-07T10:06:42.358247Z","shell.execute_reply.started":"2023-06-07T10:06:42.352761Z","shell.execute_reply":"2023-06-07T10:06:42.357171Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"7\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions=Dense(len(folders), activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:08:45.794376Z","iopub.execute_input":"2023-06-07T10:08:45.794721Z","iopub.status.idle":"2023-06-07T10:08:45.818552Z","shell.execute_reply.started":"2023-06-07T10:08:45.794692Z","shell.execute_reply":"2023-06-07T10:08:45.817689Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#create the object of the model that are used\nmodel=Model(inputs=vgg.input,outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:12:13.41379Z","iopub.execute_input":"2023-06-07T10:12:13.414143Z","iopub.status.idle":"2023-06-07T10:12:13.424326Z","shell.execute_reply.started":"2023-06-07T10:12:13.414114Z","shell.execute_reply":"2023-06-07T10:12:13.423413Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:12:28.552753Z","iopub.execute_input":"2023-06-07T10:12:28.553105Z","iopub.status.idle":"2023-06-07T10:12:28.59558Z","shell.execute_reply.started":"2023-06-07T10:12:28.553077Z","shell.execute_reply":"2023-06-07T10:12:28.594773Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten_1 (Flatten)         (None, 25088)             0         \n                                                                 \n dense (Dense)               (None, 7)                 175623    \n                                                                 \n=================================================================\nTotal params: 14,890,311\nTrainable params: 175,623\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:11:52.662095Z","iopub.execute_input":"2023-06-07T10:11:52.662447Z","iopub.status.idle":"2023-06-07T10:11:53.417672Z","shell.execute_reply.started":"2023-06-07T10:11:52.662418Z","shell.execute_reply":"2023-06-07T10:11:53.416706Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.compile(\nloss='categorical_crossentropy',\noptimizer='adam',\nmetrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:18:49.625461Z","iopub.execute_input":"2023-06-07T10:18:49.625865Z","iopub.status.idle":"2023-06-07T10:18:49.678322Z","shell.execute_reply.started":"2023-06-07T10:18:49.625832Z","shell.execute_reply":"2023-06-07T10:18:49.677447Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen=ImageDataGenerator(rescale=1./255,\n                                shear_range=0.2,\n                                zoom_range= 0.2,\n                                horizontal_flip=True)\n\ntraining_set=train_datagen.flow_from_directory('/kaggle/input/emotion-detection-fer/train',\n                                              target_size=(224,224),\n                                               batch_size=32,\n                                               class_mode='categorical'\n                                              )","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:29:43.055904Z","iopub.execute_input":"2023-06-07T10:29:43.056242Z","iopub.status.idle":"2023-06-07T10:30:16.293687Z","shell.execute_reply.started":"2023-06-07T10:29:43.056214Z","shell.execute_reply":"2023-06-07T10:30:16.292642Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Found 28709 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_datagen= ImageDataGenerator(rescale=1./255)\n\ntesting_set=test_datagen.flow_from_directory('/kaggle/input/emotion-detection-fer/test',\n                                              target_size=(224,224),\n                                               batch_size=32,\n                                               class_mode='categorical'\n                                              )","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:32:41.716918Z","iopub.execute_input":"2023-06-07T10:32:41.717273Z","iopub.status.idle":"2023-06-07T10:32:45.810086Z","shell.execute_reply.started":"2023-06-07T10:32:41.717229Z","shell.execute_reply":"2023-06-07T10:32:45.809204Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Found 7178 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Fitting the data\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r=model.fit_generator(training_set,\n                     validation_data=testing_set,\n                     epochs=5,\n                     steps_per_epoch=len(training_set),\n                     validation_steps=len(testing_set))","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:34:21.950558Z","iopub.execute_input":"2023-06-07T10:34:21.950908Z","iopub.status.idle":"2023-06-07T11:13:04.170857Z","shell.execute_reply.started":"2023-06-07T10:34:21.950877Z","shell.execute_reply":"2023-06-07T11:13:04.169907Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/187259063.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  r=model.fit_generator(training_set,\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n898/898 [==============================] - 656s 711ms/step - loss: 1.5795 - accuracy: 0.4215 - val_loss: 1.6102 - val_accuracy: 0.4464\nEpoch 2/5\n898/898 [==============================] - 410s 456ms/step - loss: 1.4493 - accuracy: 0.4815 - val_loss: 1.3831 - val_accuracy: 0.4974\nEpoch 3/5\n898/898 [==============================] - 400s 446ms/step - loss: 1.3678 - accuracy: 0.5046 - val_loss: 1.4119 - val_accuracy: 0.5011\nEpoch 4/5\n898/898 [==============================] - 415s 462ms/step - loss: 1.3440 - accuracy: 0.5209 - val_loss: 1.8753 - val_accuracy: 0.4262\nEpoch 5/5\n898/898 [==============================] - 413s 460ms/step - loss: 1.3078 - accuracy: 0.5319 - val_loss: 1.4837 - val_accuracy: 0.4894\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.models import load_model\nmodel.save(\"Emotions_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-06-07T11:20:59.682229Z","iopub.execute_input":"2023-06-07T11:20:59.682637Z","iopub.status.idle":"2023-06-07T11:20:59.814393Z","shell.execute_reply.started":"2023-06-07T11:20:59.682604Z","shell.execute_reply":"2023-06-07T11:20:59.813317Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-07T11:17:44.189854Z","iopub.execute_input":"2023-06-07T11:17:44.190205Z","iopub.status.idle":"2023-06-07T11:17:44.213358Z","shell.execute_reply.started":"2023-06-07T11:17:44.190176Z","shell.execute_reply":"2023-06-07T11:17:44.212468Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}